{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie Analysis project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope:\n",
    "In my evaluation of determining which movies do best at the box office, I wanted to focus on three main areas:\n",
    "1. What length movies and genres / genre combinations tend to produce the most revenue / highest average rating?\n",
    "2. How has domestic movie spend trended over time, and when is the best time during the year to release a movie?\n",
    "3. Which writers should be targeted for hire to maximize chances of a high grossing movie?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process:\n",
    "1. (Runtime & Genre Analysis) - Follow API instructions provided by themoviedb.org to register and generate API key and access code.  Use access code to authenticate API requests.  API results are limited to 20 results per page and 500 pages per request.  As a result, I had to split my request into smaller requests that could be returned by the API in entirety.  For this process, I decided to split each year into quarters.  For each year in the range 2000-2020, I make 4 api requests to pull in all movie data and append to a dataframe.  After all API requests are made, additional movie details are needed to pull in information on runtime and genres.  For each movie ID in my existing dataframe, I make another API call to pull in movie details associated with that ID.  Once all additional detail is pulled in, I clean data, handle missing values, replace placeholders where necessary, and evaluate the relationship between runtime and revenue.  After runtime, I move on to genres, looking at highest grossing movies on a total and median basis.  I perform the same thing for total and median average vote as well to compare differences between rating and revenue. \n",
    "\n",
    "2. (Domestic Spend Trends) - Use BeautifulSoup to scrape domestic box office spend data from boxofficemojo.com.  Once data is loaded, create scatter plots of annual and monthly revenue over time to show trends.  After this, I group the data by month to show the distribution of gross domestic spend in each month for all years.  Given the difference in variance between different months, I also decided to create a boxplot of gross domestic spend for all months.\n",
    "\n",
    "3. (Writers) - load provided datasets from IMDB.  Multiple writers can be included for each movie.  In these instances, I created a row for each individual writer.  Once I expanded writers onto new rows, I joined writer names from a provided imdb dataset and revenue from the API call to themoviedb.org performed for question 1.  Once all data was loaded, I grouped by writer name to calculate median aggregate statistics. Sort revenue column descending and produce bar charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: What length movies and genres / genre combinations tend to produce the most revenue / highest average ratings?\n",
    "\n",
    "### Movie Runtime Analysis\n",
    "Outline:\n",
    "1. Import necessary libraries\n",
    "2. Create function to build progress bar to keep track of running calculations\n",
    "3. Pull in API / Access Keys and request from TMDB API a list of movie IDs from 2000 through 2020\n",
    "4. Create function to check how many pages of requests are returned by the API\n",
    "5. Create function to loop through all returned pages to extract movie IDs and other information\n",
    "6. Create a dataframe using returned movie IDs\n",
    "7. Clean data (handle missing data, duplicates, data that does not make sense in the context of this analysis)\n",
    "8. Request movie details via API for every movie ID we have from our first set of API requests\n",
    "9. Split dataset into different buckets based on movie runtime and analyze differences in revenue / ratings\n",
    "10. Create Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.12.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (1.24.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (3.7.1)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from seaborn) (1.5.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas>=0.25->seaborn) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elvis\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\Elvis\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "##install seaborn\n",
    "import sys\n",
    "!{sys.executable} -m pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given length of calculations when calling API, I wanted a way to show status of calculations.  I followed the step-by-step instructions laid out by Bartosz Mikulski here: https://www.mikulskibartosz.name/how-to-display-a-progress-bar-in-jupyter-notebook/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start by imporing libraries\n",
    "import time, sys\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def update_progress(progress):\n",
    "    \"\"\"\n",
    "    Function to build progress bar.\n",
    "    Function returns percent of calculations remaining along with visual of progress completed so far.\n",
    "    For use in loops.\n",
    "    \"\"\"\n",
    "    bar_length = 20\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        \n",
    "    block = int(round(bar_length * progress))\n",
    "    clear_output(wait = True)\n",
    "    text = \"Progress: [{0}] {1:.1f}%\".format( \"#\" * block + \"-\" * (bar_length - block), progress * 100)\n",
    "    print(text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_keys(path):\n",
    "    \"\"\"\n",
    "    Takes a filepath as input and returns the keys of the dictionary within the file\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API instructions found here: 'https://developers.themoviedb.org/3/getting-started/introduction'\n",
    " * Register for API key\n",
    " * Enter API key on website to generate access token\n",
    " * Create necessary headers using access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use get_keys() function to pull in specific API keys and access token \n",
    "keys = get_keys('/Users/Elvis/Documents/tmdbapi.json')\n",
    "api_key = keys[\"api_key\"]\n",
    "access_token = keys['access_token']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use generated API Key and Access Token in headers to authorize access and API requests\n",
    "headers = {'Authorization': 'Bearer {}'.format(access_token)\n",
    "          ,'Content-Type': 'application/json;charset=utf-8'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_pages(url, headers, start_date, end_date):\n",
    "    \"\"\"\n",
    "    Takes as input an API url, headers containing authentication information, a start date, and end date.\n",
    "    Returns the number of pages of results returned by the API call as an int. \n",
    "    \"\"\"\n",
    "    params = {'release_date.gte': start_date,\n",
    "              'release_date.lte': end_date}\n",
    "    returned_movies = requests.get(url=url, headers=headers, params=params).json()\n",
    "    return returned_movies['total_pages']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data returned by API call is limited to 20 results per page, and a maximum of 500 pages.  Because the number of results is limited, it is not possible to pull movie data from 2000 through 2020 in one request.  As a result, each year is split into quarters.  Request quarterly data via API and append to consolidated dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movies_data(start_date, end_date, url, headers):\n",
    "    \"\"\"\n",
    "    Takes a start date, end date, API url, and headers with authentication information.\n",
    "    Uses get_num_pages function to check the number of pages returned by the API.\n",
    "    Loops through all pages, requesting data from API, concatenating results to a dataframe.\n",
    "    Returns dataframe of movie information between start and end date.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame()\n",
    "    num_pages = get_num_pages(url, headers, start_date, end_date)\n",
    "    for i in range(1, num_pages+1):\n",
    "        parameters = {'release_date.gte': start_date,\n",
    "                      'release_data.lte': end_date,\n",
    "                      'page': i}\n",
    "        request = requests.get(url, headers=headers, params=parameters).json()\n",
    "        df = pd.concat([df, pd.DataFrame(request['results'])], sort=False)\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a46e79f34d4c11223a7598a76368f7a18b43aa165775694ac821dce1e6b10059"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
